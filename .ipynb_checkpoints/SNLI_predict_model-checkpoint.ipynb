{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Inference Problem with [SNLI](https://nlp.stanford.edu/projects/snli/) Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A link to the data set and embedding can be found [here](https://drive.google.com/drive/folders/1UQ7RXktpX4XPUjCtJGQcGvb1kaHwSCty).\n",
    "In this project our main task is to implement a neural network that solves the Natural Language Inference problem on a subset of Stanford Natural Language Inference (SNLI). The task is to classify a sentence pair (premise, hypothesis) into one of the 3 categories:\n",
    " - \"entailment\" - from the first sentence is the second sentence\n",
    " - \"contradiction\" - the second sentence contradicts the first\n",
    " - \"neutral\" - the sentences are independent.\n",
    "\n",
    "We also will solve some smaller tasks while we will preparing data and creating model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I suggest to run this notebook on Google Colaboratory, performance of their services is better than performance of avarage laptop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also recommended to use Google Drive to keep dataset \"closer\" to notebook, and for this when you run the notebook on Colaboratory you need to connect and give access to your Google Drive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "D1iZTZPIZHrC",
    "outputId": "7f66948a-32ae-4d3d-eef5-0dfeae2c1c4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive', force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add to Colaboratory `hyperparameter.py` file so that it will be available for import:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 600,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "A3D1T7NNb87k",
    "outputId": "1cc46bee-86de-42f2-b525-1e72184a889b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-8f328c4b-1b7f-4749-9786-6a2aceb6c969\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-8f328c4b-1b7f-4749-9786-6a2aceb6c969\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-5c2e8a8d365b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m   result = _output.eval_js(\n\u001b[1;32m     63\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[0;32m---> 64\u001b[0;31m           input_id=input_id, output_id=output_id))\n\u001b[0m\u001b[1;32m     65\u001b[0m   \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_collections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_six\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     if (reply.get('type') == 'colab_reply' and\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "files.upload()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test if dadaset is uploaded simply check first line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IQocnNQKZ1TL"
   },
   "outputs": [],
   "source": [
    "\n",
    "# with open('./gdrive/My Drive/project/train.txt', \"r\") as f:\n",
    "#         line = f.readline()\n",
    "#         print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 82
    },
    "colab_type": "code",
    "id": "vWw4TrhrYBg7",
    "outputId": "c45356e2-e11f-4866-b7f1-9afe29199f63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mtorch-1.0.0-cp36-cp36m-cp36m-linux_x86_64.whl is not a supported wheel on this platform.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from os.path import exists\n",
    "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
    "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
    "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
    "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
    "\n",
    "\n",
    "# !pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
    "!pip install -q https://download.pytorch.org/whl/{accelerator}/torch-1.0.0-{platform}-cp36m-linux_x86_64.whl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from collections import Counter\n",
    "import pickle as pkl\n",
    "import random\n",
    "import pdb\n",
    "random.seed(134)\n",
    "\n",
    "from hyperparameter import Hyperparameter as hp\n",
    "\n",
    "\n",
    "import re\n",
    "import os "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have GPU on board we use it as far as calculations will be faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1c3wjbd-YBhR",
    "outputId": "e89edfe8-de1f-4cc3-de0d-1f07fa93379a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'device: {device}')\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "max_vocab_size = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6MVOPV9DYBhq"
   },
   "outputs": [],
   "source": [
    "def build_all_tokens(inp1, inp2):\n",
    "    all_tokens = []\n",
    "    for sent in inp1:\n",
    "        for x in sent:\n",
    "            all_tokens.append(x)   \n",
    "    for sent in inp2:\n",
    "        for x in sent:\n",
    "            all_tokens.append(x)    \n",
    "    \n",
    "    return all_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While reading data from the SNLI sets, select only those sentences in which most annotators have chosen one class (i.e. `gold_label` != \"-\"). Write out 10 first rekected sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lg-RLBKlYBhx"
   },
   "outputs": [],
   "source": [
    "def read_data(filename, count = 9999999, do_count = True):\n",
    "    rejected_amount_to_display = 10\n",
    "    rejected_count = 0\n",
    "    x1 = []\n",
    "    x2 = []\n",
    "    y = []\n",
    "    x1_w = []\n",
    "    x2_w = []\n",
    "    raw_data = []\n",
    "    filename =hp.prepath_data + filename\n",
    "    len_list = []\n",
    "    with open(filename, \"r\") as f:\n",
    "\n",
    "        line_num = 0\n",
    "        line = f.readline()\n",
    "        line = f.readline()\n",
    "        while line != None and line != \"\":\n",
    "            if do_count:\n",
    "              if line_num>count:\n",
    "                break\n",
    "            line_num += 1\n",
    "            line = line.lower()\n",
    "            arr = line.split('\\t')\n",
    "            \n",
    "            if arr[0] != '-':\n",
    "                x1_w.append(arr[5].split())\n",
    "                len_list.append(len(arr[5].split()))\n",
    "                x2_w.append(arr[6].split())\n",
    "                len_list.append(len(arr[6].split()))\n",
    "                y.append(hp.dummy2int[arr[0]])\n",
    "            else:\n",
    "                if rejected_count < rejected_amount_to_display:\n",
    "                    rejected_count+=1\n",
    "                    print(f'REJECTED {rejected_count}: {arr[5]},{arr[6]}')\n",
    "            \n",
    "            line = f.readline()\n",
    "\n",
    "        MAX_SENTENCE_LENGTH = max(len_list)\n",
    "        a = sorted(len_list, reverse = True)\n",
    "        \n",
    "        all_tokens = build_all_tokens(x1_w, x2_w)\n",
    "        print(f'read {line_num} lines')\n",
    "    return x1_w, x2_w, y, MAX_SENTENCE_LENGTH, all_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vB0eFRrpYBh6"
   },
   "outputs": [],
   "source": [
    "def build_vocab(all_tokens):\n",
    "    # Returns:\n",
    "    # id2token: list of tokens, where id2token[i] returns token that corresponds to token i\n",
    "    # token2id: dictionary where keys represent tokens and corresponding values represent indices\n",
    "    token_counter = Counter(all_tokens)\n",
    "    vocab, count = zip(*token_counter.most_common(max_vocab_size))\n",
    "    id2token = list(vocab)\n",
    "    token2id = dict(zip(vocab, range(4,4+len(vocab)))) #4 is because we add manualy '<pad>','<bos>', '<eos>', '<unk>'\n",
    "    id2token = ['<pad>','<bos>', '<eos>', '<unk>'] + id2token\n",
    "    token2id['<pad>'] = hp.PAD_IDX \n",
    "    token2id['<bos>'] = hp.BOS_IDX \n",
    "    token2id['<eos>'] = hp.EOS_IDX\n",
    "    token2id['<unk>'] = hp.UNK_IDX\n",
    "    return token2id, id2token\n",
    "\n",
    "def token2index_dataset(tokens_data, token2id):\n",
    "    indices_data = []\n",
    "    for tokens in tokens_data:\n",
    "        index_list = [token2id[token] if token in token2id else hp.UNK_IDX for token in tokens]\n",
    "        index_list = [hp.BOS_IDX] + index_list + [hp.EOS_IDX]\n",
    "        indices_data.append(index_list)\n",
    "    return indices_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 278
    },
    "colab_type": "code",
    "id": "KkSIEwIlYBiB",
    "outputId": "d2f58cd2-8ebb-4b68-a096-696c0a10aebd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REJECTED 1: a woman wearing a pink hat is looking at a pink car with the truck open.,the woman is wearing clothes.\n",
      "REJECTED 2: a man in a white jacket standing in front of an older woman in a white jacket playing crochet.,the man was playing crochet with the two women.\n",
      "REJECTED 3: a man with red earphones is working on a red and white painted hot rod from team ace racing.,a man in earphones is fixing a broken hotrod.\n",
      "REJECTED 4: a boy and a girl are walking in a mall.,a girl and a boy walking inside\n",
      "REJECTED 5: a man with sunglasses on his head is standing by signs for the wharf and ferry terminal.,a guy and his pets are waiting by the terminal.\n",
      "REJECTED 6: people relaxing under green umbrella's with a beautiful fountain in the background.,the folk is hiding from the sun under green umbrellas.\n",
      "REJECTED 7: the girl in the pink top is riding a skateboard along a white wall.,the girl is skateboarding outside.\n",
      "REJECTED 8: a man is carving a large eagle out of wood in a public setting.,the man is an artist.\n",
      "REJECTED 9: men and women wearing white swim caps giving each other piggyback rides.,men and women joking around.\n",
      "REJECTED 10: a old man in a green shirt sits on the curb holding a camera.,an old man holds a digital camera and sits on the curb.\n",
      "read 110030 lines\n",
      "MAX_SENTENCE_LENGTH: 78\n",
      "READ UNIQUE WORDS: 34325\n"
     ]
    }
   ],
   "source": [
    "count = 3000#9999999999\n",
    "train_x1, train_x2, train_y, MAX_SENTENCE_LENGTH, all_train_tokens  = read_data('train.txt', count = count, do_count = False)\n",
    "print(f'MAX_SENTENCE_LENGTH: {MAX_SENTENCE_LENGTH}')\n",
    "unique_tokens = set(all_train_tokens)\n",
    "print(f'READ UNIQUE WORDS: {len(unique_tokens)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a word encoder, we use [GloVe](https://nlp.stanford.edu/projects/glove/) embedding trained on the Wikipedia 2014 dataset (6B tokens, 400k vocabulary, 200D) (we download these embeddings, it would take too long to teach them, use file `word-vectors.txt` from thesameremote folder where trainig data is). For the embedding matrix, select only those words that appear simultaneously in GloVe and SNLI.\n",
    "\n",
    "Treat words that appear in SNLI but are not in GloVe as `<unk>`, for which the embedding vector is randomly initialized. Similarly, create two additional vectors, `<bos>`, `<eos>`, which represent the beginning and end of a sentence (modify the set of SNLI so that each sentence starts with a `<bos>` token, ends with a `<eos>` token, and for unknown words contains a `<unk>` token). Print the number of all words and words converted to `<unk>`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YqGWby2UYBiT"
   },
   "outputs": [],
   "source": [
    "token2id, id2token = build_vocab(all_train_tokens)\n",
    "\n",
    "train_x1_indices = token2index_dataset(train_x1, token2id)\n",
    "train_x2_indices = token2index_dataset(train_x2, token2id)\n",
    "\n",
    "MAX_SENTENCE_LENGTH += 2 #because we added <bos> and <eos>   \n",
    "with open(hp.prepath_data + 'word_vectors.txt') as f:\n",
    "    loaded_embeddings_ft = np.zeros((len(id2token), hp.glove_emb_dim))\n",
    "    words_ft = {}\n",
    "    idx2words_ft = {}\n",
    "    ordered_words_ft = []\n",
    "    for i, line in enumerate(f):\n",
    "        if i >= hp.words_to_load: \n",
    "            break\n",
    "        s = line.split()\n",
    "        #if the word in vocabulary is in fasttext, we load the embedding for that word.\n",
    "        if s[0] in token2id:\n",
    "            idx = token2id[s[0]]\n",
    "            loaded_embeddings_ft[idx] = np.asarray(s[1:])\n",
    "unk_tokens_idx = []\n",
    "loaded_embeddings_ft[0] = np.random.rand(hp.glove_emb_dim) #<pad>\n",
    "loaded_embeddings_ft[1] = np.random.rand(hp.glove_emb_dim) #<bos>\n",
    "loaded_embeddings_ft[2] = np.random.rand(hp.glove_emb_dim) #<eos>\n",
    "loaded_embeddings_ft[3] = np.random.rand(hp.glove_emb_dim) #<unk>\n",
    "for i in range(3, len(id2token)):\n",
    "    if loaded_embeddings_ft[i][0] == 0:\n",
    "        #if the word in vocabulary is not in fasttext(include unk, bos, eos), we initialize a random vector.\n",
    "        loaded_embeddings_ft[i] = np.random.rand(hp.glove_emb_dim)\n",
    "        unk_tokens_idx.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "4qDkTCOKYBib",
    "outputId": "503ba68d-5690-4199-d786-2006e4a01f88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "READ WORDS: 2225693\n",
      "READ <unk> WORDS: 8041\n"
     ]
    }
   ],
   "source": [
    "print(f'READ WORDS: {len(all_train_tokens)}')\n",
    "unk_words_read = 0\n",
    "#replace unknown words with <unk>\n",
    "for i,_ in enumerate(train_x1_indices):\n",
    "    for j,_ in enumerate(train_x1_indices[i]):\n",
    "        if train_x1_indices[i][j] in unk_tokens_idx:\n",
    "            train_x1_indices[i][j] = hp.UNK_IDX\n",
    "\n",
    "print(f'READ <unk> WORDS: {len(unk_tokens_idx)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 261
    },
    "colab_type": "code",
    "id": "FoDWYS_uYBii",
    "outputId": "ef2a3dc1-46e0-4e42-8119-177626318e59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'text' already exists and is not an empty directory.\n",
      "REJECTED 1: the middle eastern woman wearing the pink headscarf is walking beside a woman in a purple headscarf.,two women are walking together.\n",
      "REJECTED 2: a white-haired man with a mustache and glasses in a business suit stands outside at a podium marked with the seal of the us house of representatives, surrounded by many people, with a columned building behind him.,there are people outside.\n",
      "REJECTED 3: a group of people sit on benches at a park outside a building.,a women sits on a bench by herself.\n",
      "REJECTED 4: two male police officers on patrol, wearing the normal gear and bright green reflective shirts.,the two male police officers are looking for trouble.\n",
      "REJECTED 5: a restaurant front line, with a warmer in the front and a person in a red coca cola shirt cooking.,the person in the coca cola shirt is opening the refrigerator.\n",
      "REJECTED 6: several children are standing with plates full of food under a shelter, watching a man in a purple shirt serving good.,the children are about to get food.\n",
      "REJECTED 7: several children are standing with plates full of food under a shelter, watching a man in a purple shirt serving good.,the children are inside.\n",
      "REJECTED 8: a woman holds her child out of a red window, next to a color tv sign.,the woman is extending her arms.\n",
      "REJECTED 9: a woman holds her child out of a red window, next to a color tv sign.,the child is a daughter.\n",
      "REJECTED 10: a little girl sitting in a seat.,she is sitting nicely.\n",
      "read 10000 lines\n",
      "Data Loaded\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/pytorch/text.git\n",
    "from text.torchtext import data\n",
    "from text.torchtext import datasets\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "class SNLIDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Class that represents a train/validation/test dataset that's readable for PyTorch\n",
    "    Note that this class inherits torch.utils.data.Dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_list1, data_list2,target_list):\n",
    "        \"\"\"\n",
    "        @param data_list: list of SNLI tokens \n",
    "        @param target_list: list of SNLI targets \n",
    "\n",
    "        \"\"\"\n",
    "        self.data_list1 = data_list1\n",
    "        self.data_list2 = data_list2\n",
    "        self.target_list = target_list\n",
    "        assert (len(self.data_list1) == len(self.target_list))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list1)\n",
    "        \n",
    "    def __getitem__(self, key):\n",
    "        \"\"\"\n",
    "        Triggered when you call dataset[i]\n",
    "        \"\"\"\n",
    "        \n",
    "        token_idx1 = self.data_list1[key][:MAX_SENTENCE_LENGTH]\n",
    "        token_idx2 = self.data_list2[key][:MAX_SENTENCE_LENGTH]\n",
    "        label = self.target_list[key]\n",
    "        return [token_idx1, token_idx2, len(token_idx1), len(token_idx2),label]\n",
    "def SNLI_collate_func(batch):\n",
    "    \"\"\"\n",
    "    Customized function for DataLoader that dynamically pads the batch so that all \n",
    "    data have the same length\n",
    "    \"\"\"\n",
    "    data_list1 = []\n",
    "    data_list2 = []\n",
    "    label_list = []\n",
    "    length_list1 = []\n",
    "    length_list2 = []\n",
    "    for datum in batch:\n",
    "        label_list.append(datum[4])\n",
    "        length_list1.append(datum[2])\n",
    "        length_list2.append(datum[3])\n",
    "    # padding\n",
    "    batch_max_sent_len = max(max(length_list1), max(length_list2))\n",
    "    for datum in batch:\n",
    "        padded_vec1 = np.pad(np.array(datum[0]), \n",
    "                                pad_width=((0,batch_max_sent_len-datum[2])), \n",
    "                                mode=\"constant\", constant_values=0)\n",
    "        padded_vec2 = np.pad(np.array(datum[1]), \n",
    "                                pad_width=((0,batch_max_sent_len-datum[3])), \n",
    "                                mode=\"constant\", constant_values=0)\n",
    "        data_list1.append(padded_vec1)\n",
    "        data_list2.append(padded_vec2)\n",
    "    \n",
    "    #transform labels to one hot label to fit into cross-entropy loss\n",
    "    # define example\n",
    "    \n",
    "    return [torch.from_numpy(np.array(data_list1)), torch.from_numpy(np.array(data_list2)),\n",
    "            torch.LongTensor(length_list1), torch.LongTensor(length_list2),torch.LongTensor(label_list)]\n",
    "\n",
    "#data loader\n",
    "train_dataset = SNLIDataset(train_x1_indices, train_x2_indices,train_y)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=SNLI_collate_func,\n",
    "                                           shuffle=True)\n",
    "val_x1, val_x2, val_y, _, _  = read_data('dev.txt', count = count, do_count = False)\n",
    "\n",
    "\n",
    "val_x1_indices = token2index_dataset(val_x1, token2id)\n",
    "val_x2_indices = token2index_dataset(val_x2, token2id)\n",
    "val_dataset = SNLIDataset(val_x1_indices, val_x2_indices, val_y)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=SNLI_collate_func,\n",
    "                                           shuffle=True)\n",
    "print('Data Loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WYjEPAr1YBis"
   },
   "outputs": [],
   "source": [
    "def create_emb_layer(weights_matrix, non_trainable=False):\n",
    "    weights_matrix = torch.from_numpy(weights_matrix)\n",
    "    if str(device).startswith('cuda'):\n",
    "        weights_matrix = weights_matrix.cuda()\n",
    "    num_embeddings, embedding_dim = weights_matrix.size()\n",
    "    emb_layer = nn.Embedding(num_embeddings, embedding_dim)\n",
    "    emb_layer.load_state_dict({'weight': weights_matrix})\n",
    "    if non_trainable:\n",
    "        emb_layer.weight.requires_grad = False\n",
    "\n",
    "    return emb_layer, num_embeddings, embedding_dim\n",
    "\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, weights_matrix, hidden_size, classset_size):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.embedding, num_embeddings, embedding_dim = create_emb_layer(weights_matrix, True)\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.lstm1 = nn.LSTM(embedding_dim, hidden_size)\n",
    "        self.lstm2 = nn.LSTM(embedding_dim, hidden_size)\n",
    "        self.linear1 = nn.Sequential(nn.Linear(self.hidden_size*2, self.hidden_size*2), nn.ReLU())\n",
    "        self.hidden2tag = nn.Linear(hidden_size*2, classset_size)\n",
    "        \n",
    "\n",
    "    def forward(self, x1, x2, x1_len, x2_len):\n",
    "        # reset hidden state\n",
    "        batch_size, seq_len = x1.size()\n",
    "        embed1 = self.embedding(x1)\n",
    "        embed2 = self.embedding(x2)\n",
    "        self.hidden = self.init_hidden(batch_size, seq_len)\n",
    "        if str(device).startswith('cuda'):\n",
    "            self.hidden = (self.hidden[0].cuda(), self.hidden[1].cuda())\n",
    "        lstm_out1, self.hidden1 = self.lstm1(embed1, self.hidden) #batch_size * maximum sentence length * hidden_size\n",
    "        lstm_out2, self.hidden2 = self.lstm2(embed2, self.hidden)\n",
    "        lstm_out1_lasts = torch.zeros(batch_size, self.hidden_size) #batch_size * hidden_size\n",
    "        #find the <eos> word and get it's output\n",
    "        for i, out1 in enumerate(lstm_out1):\n",
    "            if len(out1) == x1_len[i]:\n",
    "                lstm_out1_lasts[i] = out1[-1, :]\n",
    "            else:\n",
    "                lstm_out1_lasts[i] = out1[x1_len[i]-1, :]\n",
    "        lstm_out2_lasts = torch.zeros(batch_size, self.hidden_size) #batch_size * hidden_size\n",
    "        for i, out2 in enumerate(lstm_out2):\n",
    "            if len(out2) == x2_len[i]:\n",
    "                lstm_out2_lasts[i] = out2[-1, :]\n",
    "            else:\n",
    "                lstm_out2_lasts[i] = out2[x2_len[i]-1, :]\n",
    "        out_pool = torch.cat((lstm_out1_lasts, lstm_out2_lasts),1)  #todo: batch size * 2 * word_embedding\n",
    "        out_pool = out_pool.to(device)\n",
    "        after_relu = self.linear1(out_pool)\n",
    "        linear_to_classes = self.hidden2tag(after_relu)\n",
    "        class_scores = F.log_softmax(linear_to_classes, dim=1)\n",
    "        return class_scores\n",
    "    \n",
    "    def init_hidden(self, batch_size, seq_len):\n",
    "        return (torch.zeros( 1, seq_len, self.hidden_size),\n",
    "               torch.zeros( 1, seq_len, self.hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "lkxUKqFyYBi2",
    "outputId": "4cafdbe9-3df7-456e-f68e-33b3b8cbe039"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "switching model to cuda mode...\n",
      "Model Built, start trainning\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = LSTMClassifier(loaded_embeddings_ft, hp.glove_emb_dim, len(hp.dummy2int))\n",
    "if str(device).startswith('cuda'):\n",
    "    print('switching model to cuda mode...')\n",
    "    model.cuda()\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
    "print('Model Built, start trainning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2w24VrjCYBjG"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "import time\n",
    "def test_model(loader, model, criterion):\n",
    "    \"\"\"\n",
    "    Help function that tests the model's performance on a dataset\n",
    "    @param: loader - data loader for the dataset to test against\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    losses = AverageMeter()\n",
    "    for i, (x1, x2, lengths1, lengths2, labels) in enumerate(loader):\n",
    "        if i % 200 == 0:\n",
    "            print(f'epoch {epoch}, test batch {i}')\n",
    "        x1, x2, labels = x1.to(device), x2.to(device), labels.to(device)\n",
    "        # Forward pass\n",
    "        if str(device).startswith('cuda'):\n",
    "            x1, x2 = x1.cuda(), x2.cuda()\n",
    "        outputs = model(x1, x2, lengths1, lengths2)\n",
    "        outputs_softmax = F.softmax(outputs, dim=1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        losses.update(loss, x1.size(0))\n",
    "        predicted = outputs_softmax.max(1, keepdim=True)[1]\n",
    "\n",
    "        total += labels.size(0)\n",
    "\n",
    "        correct += predicted.eq(labels.view_as(predicted)).sum().item()\n",
    "    return (100 * correct / total), losses.avg\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "def train_plot(train_loss, val_loss, val_acc, fname):\n",
    "\n",
    "    if not os.path.exists('fig'):\n",
    "        os.makedirs('fig')\n",
    "    fig_dir = './fig/'\n",
    "    plt.figure()\n",
    "    plt.plot(train_loss,label='Training Loss')\n",
    "    plt.plot(val_loss,label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(fig_dir + 'loss'+ '_(' + fname + ').png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 4682
    },
    "colab_type": "code",
    "id": "b6A83fyzYBjT",
    "outputId": "0ea59a6a-3796-4786-87a4-5e2de6681f7a",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, train batch 0\n",
      "epoch 0, train batch 200\n",
      "epoch 0, train batch 400\n",
      "validation...\n",
      "epoch 0, test batch 0\n",
      "epoch 0, test batch 200\n",
      " Epoch: [1/5], Step: [401/3434], Training loss: 1.0839, Validation Acc: 40.43893517577728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:250: UserWarning: Couldn't retrieve source code for container of type LSTMClassifier. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, train batch 600\n",
      "epoch 0, train batch 800\n",
      "validation...\n",
      "epoch 0, test batch 0\n",
      "epoch 0, test batch 200\n",
      " Epoch: [1/5], Step: [801/3434], Training loss: 1.0816, Validation Acc: 40.20524283682178\n",
      "epoch 0, train batch 1000\n",
      "epoch 0, train batch 1200\n",
      "validation...\n",
      "epoch 0, test batch 0\n",
      "epoch 0, test batch 200\n",
      " Epoch: [1/5], Step: [1201/3434], Training loss: 1.0803, Validation Acc: 40.20524283682178\n",
      "epoch 0, train batch 1400\n",
      "epoch 0, train batch 1600\n",
      "validation...\n",
      "epoch 0, test batch 0\n",
      "epoch 0, test batch 200\n",
      " Epoch: [1/5], Step: [1601/3434], Training loss: 1.0799, Validation Acc: 40.77423287949604\n",
      "epoch 0, train batch 1800\n",
      "epoch 0, train batch 2000\n",
      "validation...\n",
      "epoch 0, test batch 0\n",
      "epoch 0, test batch 200\n",
      " Epoch: [1/5], Step: [2001/3434], Training loss: 1.0797, Validation Acc: 40.78439341597236\n",
      "epoch 0, train batch 2200\n",
      "epoch 0, train batch 2400\n",
      "validation...\n",
      "epoch 0, test batch 0\n",
      "epoch 0, test batch 200\n",
      " Epoch: [1/5], Step: [2401/3434], Training loss: 1.0789, Validation Acc: 40.55070107701687\n",
      "epoch 0, train batch 2600\n",
      "epoch 0, train batch 2800\n",
      "validation...\n",
      "epoch 0, test batch 0\n",
      "epoch 0, test batch 200\n",
      " Epoch: [1/5], Step: [2801/3434], Training loss: 1.0782, Validation Acc: 41.35338345864662\n",
      "epoch 0, train batch 3000\n",
      "epoch 0, train batch 3200\n",
      "validation...\n",
      "epoch 0, test batch 0\n",
      "epoch 0, test batch 200\n",
      " Epoch: [1/5], Step: [3201/3434], Training loss: 1.0779, Validation Acc: 40.510058931111566\n",
      "epoch 0, train batch 3400\n",
      "epoch 1, train batch 0\n",
      "epoch 1, train batch 200\n",
      "epoch 1, train batch 400\n",
      "validation...\n",
      "epoch 1, test batch 0\n",
      "epoch 1, test batch 200\n",
      " Epoch: [2/5], Step: [401/3434], Training loss: 1.0786, Validation Acc: 40.885998780735626\n",
      "epoch 1, train batch 600\n",
      "epoch 1, train batch 800\n",
      "validation...\n",
      "epoch 1, test batch 0\n",
      "epoch 1, test batch 200\n",
      " Epoch: [2/5], Step: [801/3434], Training loss: 1.0769, Validation Acc: 41.27209916683601\n",
      "epoch 1, train batch 1000\n",
      "epoch 1, train batch 1200\n",
      "validation...\n",
      "epoch 1, test batch 0\n",
      "epoch 1, test batch 200\n",
      " Epoch: [2/5], Step: [1201/3434], Training loss: 1.0765, Validation Acc: 41.62771794350742\n",
      "epoch 1, train batch 1400\n",
      "epoch 1, train batch 1600\n",
      "validation...\n",
      "epoch 1, test batch 0\n",
      "epoch 1, test batch 200\n",
      " Epoch: [2/5], Step: [1601/3434], Training loss: 1.0764, Validation Acc: 40.662466978256454\n",
      "epoch 1, train batch 1800\n",
      "epoch 1, train batch 2000\n",
      "validation...\n",
      "epoch 1, test batch 0\n",
      "epoch 1, test batch 200\n",
      " Epoch: [2/5], Step: [2001/3434], Training loss: 1.0760, Validation Acc: 40.134119081487505\n",
      "epoch 1, train batch 2200\n",
      "epoch 1, train batch 2400\n",
      "validation...\n",
      "epoch 1, test batch 0\n",
      "epoch 1, test batch 200\n",
      " Epoch: [2/5], Step: [2401/3434], Training loss: 1.0755, Validation Acc: 40.946961999593576\n",
      "epoch 1, train batch 2600\n",
      "epoch 1, train batch 2800\n",
      "validation...\n",
      "epoch 1, test batch 0\n",
      "epoch 1, test batch 200\n",
      " Epoch: [2/5], Step: [2801/3434], Training loss: 1.0754, Validation Acc: 40.9164803901646\n",
      "epoch 1, train batch 3000\n",
      "epoch 1, train batch 3200\n",
      "validation...\n",
      "epoch 1, test batch 0\n",
      "epoch 1, test batch 200\n",
      " Epoch: [2/5], Step: [3201/3434], Training loss: 1.0753, Validation Acc: 40.38813249339565\n",
      "epoch 1, train batch 3400\n",
      "epoch 2, train batch 0\n",
      "epoch 2, train batch 200\n",
      "epoch 2, train batch 400\n",
      "validation...\n",
      "epoch 2, test batch 0\n",
      "epoch 2, test batch 200\n",
      " Epoch: [3/5], Step: [401/3434], Training loss: 1.0737, Validation Acc: 40.58118268644584\n",
      "epoch 2, train batch 600\n",
      "epoch 2, train batch 800\n",
      "validation...\n",
      "epoch 2, test batch 0\n",
      "epoch 2, test batch 200\n",
      " Epoch: [3/5], Step: [801/3434], Training loss: 1.0743, Validation Acc: 40.703109124161756\n",
      "epoch 2, train batch 1000\n",
      "epoch 2, train batch 1200\n",
      "validation...\n",
      "epoch 2, test batch 0\n",
      "epoch 2, test batch 200\n",
      " Epoch: [3/5], Step: [1201/3434], Training loss: 1.0755, Validation Acc: 40.76407234301971\n",
      "epoch 2, train batch 1400\n",
      "epoch 2, train batch 1600\n",
      "validation...\n",
      "epoch 2, test batch 0\n",
      "epoch 2, test batch 200\n",
      " Epoch: [3/5], Step: [1601/3434], Training loss: 1.0748, Validation Acc: 41.1908148750254\n",
      "epoch 2, train batch 1800\n",
      "epoch 2, train batch 2000\n",
      "validation...\n",
      "epoch 2, test batch 0\n",
      "epoch 2, test batch 200\n",
      " Epoch: [3/5], Step: [2001/3434], Training loss: 1.0745, Validation Acc: 40.002032107295264\n",
      "epoch 2, train batch 2200\n",
      "epoch 2, train batch 2400\n",
      "validation...\n",
      "epoch 2, test batch 0\n",
      "epoch 2, test batch 200\n",
      " Epoch: [3/5], Step: [2401/3434], Training loss: 1.0746, Validation Acc: 40.997764681975205\n",
      "epoch 2, train batch 2600\n",
      "epoch 2, train batch 2800\n",
      "validation...\n",
      "epoch 2, test batch 0\n",
      "epoch 2, test batch 200\n",
      " Epoch: [3/5], Step: [2801/3434], Training loss: 1.0749, Validation Acc: 40.34749034749035\n",
      "epoch 2, train batch 3000\n",
      "epoch 2, train batch 3200\n",
      "validation...\n",
      "epoch 2, test batch 0\n",
      "epoch 2, test batch 200\n",
      " Epoch: [3/5], Step: [3201/3434], Training loss: 1.0749, Validation Acc: 40.24588498272709\n",
      "epoch 2, train batch 3400\n",
      "epoch 3, train batch 0\n",
      "epoch 3, train batch 200\n",
      "epoch 3, train batch 400\n",
      "validation...\n",
      "epoch 3, test batch 0\n",
      "epoch 3, test batch 200\n",
      " Epoch: [4/5], Step: [401/3434], Training loss: 1.0755, Validation Acc: 40.65230644178013\n",
      "epoch 3, train batch 600\n",
      "epoch 3, train batch 800\n",
      "validation...\n",
      "epoch 3, test batch 0\n",
      "epoch 3, test batch 200\n",
      " Epoch: [4/5], Step: [801/3434], Training loss: 1.0740, Validation Acc: 41.414346677504575\n",
      "epoch 3, train batch 1000\n",
      "epoch 3, train batch 1200\n",
      "validation...\n",
      "epoch 3, test batch 0\n",
      "epoch 3, test batch 200\n",
      " Epoch: [4/5], Step: [1201/3434], Training loss: 1.0743, Validation Acc: 40.72343019711441\n",
      "epoch 3, train batch 1400\n",
      "epoch 3, train batch 1600\n",
      "validation...\n",
      "epoch 3, test batch 0\n",
      "epoch 3, test batch 200\n",
      " Epoch: [4/5], Step: [1601/3434], Training loss: 1.0749, Validation Acc: 40.936801463117256\n",
      "epoch 3, train batch 1800\n",
      "epoch 3, train batch 2000\n",
      "validation...\n",
      "epoch 3, test batch 0\n",
      "epoch 3, test batch 200\n",
      " Epoch: [4/5], Step: [2001/3434], Training loss: 1.0746, Validation Acc: 40.753911806543385\n",
      "epoch 3, train batch 2200\n",
      "epoch 3, train batch 2400\n",
      "validation...\n",
      "epoch 3, test batch 0\n",
      "epoch 3, test batch 200\n",
      " Epoch: [4/5], Step: [2401/3434], Training loss: 1.0745, Validation Acc: 40.82503556187767\n",
      "epoch 3, train batch 2600\n",
      "epoch 3, train batch 2800\n",
      "validation...\n",
      "epoch 3, test batch 0\n",
      "epoch 3, test batch 200\n",
      " Epoch: [4/5], Step: [2801/3434], Training loss: 1.0744, Validation Acc: 40.560861613493195\n",
      "epoch 3, train batch 3000\n",
      "epoch 3, train batch 3200\n",
      "validation...\n",
      "epoch 3, test batch 0\n",
      "epoch 3, test batch 200\n",
      " Epoch: [4/5], Step: [3201/3434], Training loss: 1.0739, Validation Acc: 41.35338345864662\n",
      "epoch 3, train batch 3400\n",
      "epoch 4, train batch 0\n",
      "epoch 4, train batch 200\n",
      "epoch 4, train batch 400\n",
      "validation...\n",
      "epoch 4, test batch 0\n",
      "epoch 4, test batch 200\n",
      " Epoch: [5/5], Step: [401/3434], Training loss: 1.0759, Validation Acc: 40.33732981101402\n",
      "epoch 4, train batch 600\n",
      "epoch 4, train batch 800\n",
      "validation...\n",
      "epoch 4, test batch 0\n",
      "epoch 4, test batch 200\n",
      " Epoch: [5/5], Step: [801/3434], Training loss: 1.0754, Validation Acc: 40.906319853688274\n",
      "epoch 4, train batch 1000\n",
      "epoch 4, train batch 1200\n",
      "validation...\n",
      "epoch 4, test batch 0\n",
      "epoch 4, test batch 200\n",
      " Epoch: [5/5], Step: [1201/3434], Training loss: 1.0750, Validation Acc: 40.235724446250764\n",
      "epoch 4, train batch 1400\n",
      "epoch 4, train batch 1600\n",
      "validation...\n",
      "epoch 4, test batch 0\n",
      "epoch 4, test batch 200\n",
      " Epoch: [5/5], Step: [1601/3434], Training loss: 1.0742, Validation Acc: 41.30258077626499\n",
      "epoch 4, train batch 1800\n",
      "epoch 4, train batch 2000\n",
      "validation...\n",
      "epoch 4, test batch 0\n",
      "epoch 4, test batch 200\n",
      " Epoch: [5/5], Step: [2001/3434], Training loss: 1.0744, Validation Acc: 40.936801463117256\n",
      "epoch 4, train batch 2200\n",
      "epoch 4, train batch 2400\n",
      "validation...\n",
      "epoch 4, test batch 0\n",
      "epoch 4, test batch 200\n",
      " Epoch: [5/5], Step: [2401/3434], Training loss: 1.0745, Validation Acc: 40.81487502540134\n",
      "epoch 4, train batch 2600\n",
      "epoch 4, train batch 2800\n",
      "validation...\n",
      "epoch 4, test batch 0\n",
      "epoch 4, test batch 200\n",
      " Epoch: [5/5], Step: [2801/3434], Training loss: 1.0741, Validation Acc: 40.8758382442593\n",
      "epoch 4, train batch 3000\n",
      "epoch 4, train batch 3200\n",
      "validation...\n",
      "epoch 4, test batch 0\n",
      "epoch 4, test batch 200\n",
      " Epoch: [5/5], Step: [3201/3434], Training loss: 1.0739, Validation Acc: 41.10953058321479\n",
      "epoch 4, train batch 3400\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgAAAAFYCAYAAAAlTUT9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_acc = 41.62771794350742\n"
     ]
    }
   ],
   "source": [
    "#train the model\n",
    "from tqdm import tnrange, tqdm_notebook, tqdm\n",
    "num_epochs = 5\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_acc, val_loss = None, None\n",
    "val_accs = []\n",
    "if not os.path.exists('saved_model'):\n",
    "    os.makedirs('saved_model')\n",
    "save_model = 1\n",
    "best_acc = 0\n",
    "for epoch in range(num_epochs):\n",
    "    losses = AverageMeter()\n",
    "    for i, (x1, x2, lengths1, lengths2, labels) in enumerate(train_loader):\n",
    "        if i % 200 == 0:\n",
    "            print(f'epoch {epoch}, train batch {i}')\n",
    "        x1, x2, labels = x1.to(device), x2.to(device), labels.to(device)\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        if str(device).startswith('cuda'):\n",
    "            x1, x2 = x1.cuda(), x2.cuda()\n",
    "        outputs = model(x1, x2, lengths1, lengths2)\n",
    "        loss = criterion(outputs, labels)\n",
    "        losses.update(loss, x1.size(0))\n",
    "        # Backward and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # test every 100 iterations\n",
    "        if i > 0 and i % 400 == 0:\n",
    "            # test\n",
    "            print('validation...')\n",
    "            val_acc, val_loss = test_model(val_loader, model, criterion)\n",
    "            print(' Epoch: [{}/{}], Step: [{}/{}], Training loss: {loss.avg:.4f}, Validation Acc: {}'.format(\n",
    "                       epoch+1, num_epochs, i+1, len(train_loader), val_acc, loss = losses))\n",
    "            if val_acc > best_acc:\n",
    "                best_acc = val_acc\n",
    "            if save_model > 0:    \n",
    "                torch.save(model, f'./saved_model/snli_epoch_{epoch}_model.pth')\n",
    "\n",
    "    train_losses.append(losses.avg) \n",
    "    if val_loss is not None:\n",
    "        val_losses.append(val_loss)\n",
    "    if val_acc is not None:\n",
    "        val_accs.append(val_acc)\n",
    "        \n",
    "args_str = 'model = ' + str('model') + 'hidden size = ' + str(200)\n",
    "train_plot(train_losses,val_losses, val_accs, fname = args_str)\n",
    "print('best_acc = ' + str(best_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "colab_type": "code",
    "id": "EW6drvwQYBkE",
    "outputId": "53154ea4-ab56-418f-b9e6-e140d2c55bb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REJECTED 1: during calf roping a cowboy calls off his horse.,cowboy falling off horse.\n",
      "REJECTED 2: a ford car is making a right turn as 3 males are walking across the street behind the car.,a car proceeding straight as pedestrians walked across the road in back of it.\n",
      "REJECTED 3: an old woman watches a man look down at some balls on the ground.,a gray haired person is looking at a gentleman.\n",
      "REJECTED 4: a bird is flapping its wings on the water.,the bird is floating on the water.\n",
      "REJECTED 5: young woman is putting her clothes in the dryer portion of a double stacked washer and dryer unit.,a tall person drying clothes\n",
      "REJECTED 6: a woman, standing behind a girl, helping the girl with an experiment.,a woman is sitting next to a girl while they finish an experiment.\n",
      "REJECTED 7: two street people and a dog sitting on the ground and one is holding an \"out of luck\" sign.,the people are swimming in the red sea\n",
      "REJECTED 8: violin soloists take the stage during the orchestra's opening show at the theater.,people are playing a violin solo for a crowd.\n",
      "REJECTED 9: a man is painting a picture outside behind a crowd.,a man is punching a picture to show great anger and rage outside to people.\n",
      "REJECTED 10: elderly woman in blue apron balances a basket on her head on a sidewalk while talking to a woman dressed in black.,the elderly woman is knitting a scarf for the woman she is talking to.\n",
      "read 3001 lines\n",
      "switching model to cuda mode...\n",
      "test\n",
      "epoch 4, test batch 0\n",
      "Test Acc: 41.692150866462796\n"
     ]
    }
   ],
   "source": [
    "test_x1, test_x2, test_y, _, _  = read_data('test.txt', count = count, do_count = True)\n",
    "\n",
    "\n",
    "test_x1_indices = token2index_dataset(test_x1, token2id)\n",
    "test_x2_indices = token2index_dataset(test_x2, token2id)\n",
    "test_dataset = SNLIDataset(test_x1_indices, test_x2_indices, test_y)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=SNLI_collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "run_model = model#torch.load('./saved_model/snli_epoch_4_sgd_model.pth', map_location='cpu')\n",
    "\n",
    "if str(device).startswith('cuda'):\n",
    "    print('switching model to cuda mode...')\n",
    "    run_model.cuda()\n",
    "print('test')\n",
    "test_acc, test_loss = test_model(test_loader, run_model, criterion)\n",
    "print('Test Acc: {}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "PeTDn2yi8tNO",
    "outputId": "f5d617da-900b-4870-efb9-afae96f2685f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41.963982330954806"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5zXgF-GHYBkJ"
   },
   "outputs": [],
   "source": [
    "# output the 3 correct and 3 wrong examples\n",
    "# labels are: {'contradiction': 0, 'entailment': 1, 'neutral': 2}\n",
    "correct = 0\n",
    "total = 0\n",
    "model.eval()\n",
    "count_right, count_wrong = 0,0\n",
    "rights1 = []\n",
    "wrongs1 = []\n",
    "rights2 = []\n",
    "wrongs2 = []\n",
    "right_label = []\n",
    "wrong_label_pred = []\n",
    "wrong_label_true = []\n",
    "\n",
    "for x1, x2, lengths1, lengths2, labels in val_loader:\n",
    "    x1 = x1.to(device)\n",
    "    x2 = x2.to(device)\n",
    "    labels = labels.to(device)\n",
    "    outputs = run_model(x1, x2, lengths1, lengths2)\n",
    "    predicted = outputs.min(1, keepdim=True)[1]\n",
    "    i = 0\n",
    "    while (count_right < 3 or count_wrong<4) and i<len(predicted):\n",
    "        pred = predicted[i]\n",
    "        \n",
    "        true = labels[i]\n",
    "        if pred[0] == true:\n",
    "            if count_right<3:\n",
    "                if true not in right_label:\n",
    "                    rights1.append(x1[i,:].cpu().data.numpy())\n",
    "                    rights2.append(x2[i,:].cpu().data.numpy())\n",
    "                    right_label.append(true)\n",
    "                    count_right += 1\n",
    "        else:\n",
    "            if true not in wrong_label_true:\n",
    "                wrongs1.append(x1[i,:].cpu().data.numpy())\n",
    "                wrongs2.append(x2[i,:].cpu().data.numpy())\n",
    "                wrong_label_pred.append(pred)\n",
    "                wrong_label_true.append(true)\n",
    "                count_wrong += 1\n",
    "        i += 1\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "id": "VnApJvJsYBkL",
    "outputId": "12613a0b-570e-473f-b9d1-c5a06c118e9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos> a woman walking a dog on a leash at the beach, trailing behind as a pug follows another unseen woman. <eos>\n",
      "<bos> a large woman walks a dog <eos>\n",
      "label: 2\n",
      "**************\n"
     ]
    }
   ],
   "source": [
    "for sent1, sent2, label in zip(rights1, rights2, right_label):\n",
    "    output = []\n",
    "    for index in sent1:\n",
    "        if index != hp.PAD_IDX:\n",
    "            output.append(id2token[index])\n",
    "    print((' ').join(output))\n",
    "    output = []\n",
    "    for index in sent2:\n",
    "        if index != hp.PAD_IDX:\n",
    "            output.append(id2token[index])\n",
    "    print((' ').join(output))\n",
    "    print(f'label: {label.item()}')\n",
    "    print('**************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "h_5DOaDeYBkQ",
    "outputId": "2a908944-ba21-4639-fae1-35a7e8b629cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos> two young children on a skateboard going across a sidewalk <eos>\n",
      "<bos> two young children riding on a bike. <eos>\n",
      "pred label: 2, true label: 0\n",
      "**************\n",
      "<bos> a skier is jumping in the air over a <unk> near a mountain range. <eos>\n",
      "<bos> a skier performs a competitive technical jump during a competition. <eos>\n",
      "pred label: 1, true label: 2\n",
      "**************\n",
      "<bos> children and adults swim in large pool with red staircase. <eos>\n",
      "<bos> a group of people are swimming. <eos>\n",
      "pred label: 2, true label: 1\n",
      "**************\n"
     ]
    }
   ],
   "source": [
    "for sent1, sent2, pred, true in zip(wrongs1, wrongs2, wrong_label_pred, wrong_label_true):\n",
    "    output = []\n",
    "    for index in sent1:\n",
    "        if index != hp.PAD_IDX:\n",
    "            output.append(id2token[index])\n",
    "    print((' ').join(output))\n",
    "    output = []\n",
    "    for index in sent2:\n",
    "        if index != hp.PAD_IDX:\n",
    "            output.append(id2token[index])\n",
    "    print((' ').join(output))\n",
    "    print(f'pred label: {pred.item()}, true label: {true.item()}')\n",
    "    print('**************')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "SNLI predict model-2-drive.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
